{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import copy\n",
    "import random as rand\n",
    "\n",
    "data = pd.read_csv(\"c:\\\\Users\\\\markm\\\\Desktop\\\\CAPSTONE\\\\capstone\\\\data\\\\external\\\\watson_healthcare_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>Shift</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313919</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200302</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060315</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272912</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1414939</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  Age Attrition     BusinessTravel  DailyRate  Department  \\\n",
       "0     1313919   41        No      Travel_Rarely       1102  Cardiology   \n",
       "1     1200302   49        No  Travel_Frequently        279   Maternity   \n",
       "2     1060315   37       Yes      Travel_Rarely       1373   Maternity   \n",
       "3     1272912   33        No  Travel_Frequently       1392   Maternity   \n",
       "4     1414939   27        No      Travel_Rarely        591   Maternity   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  ...  \\\n",
       "0                 1          2  Life Sciences              1  ...   \n",
       "1                 8          1  Life Sciences              1  ...   \n",
       "2                 2          2          Other              1  ...   \n",
       "3                 3          4  Life Sciences              1  ...   \n",
       "4                 2          1        Medical              1  ...   \n",
       "\n",
       "   RelationshipSatisfaction StandardHours  Shift  TotalWorkingYears  \\\n",
       "0                         1            80      0                  8   \n",
       "1                         4            80      1                 10   \n",
       "2                         2            80      0                  7   \n",
       "3                         3            80      0                  8   \n",
       "4                         4            80      1                  6   \n",
       "\n",
       "   TrainingTimesLastYear WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                      0               1               6                  4   \n",
       "1                      3               3              10                  7   \n",
       "2                      3               3               0                  0   \n",
       "3                      3               3               8                  7   \n",
       "4                      3               3               2                  2   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                     5  \n",
       "1                        1                     7  \n",
       "2                        0                     0  \n",
       "3                        3                     0  \n",
       "4                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeID                1676 non-null   int64 \n",
      " 1   Age                       1676 non-null   int64 \n",
      " 2   Attrition                 1676 non-null   object\n",
      " 3   BusinessTravel            1676 non-null   object\n",
      " 4   DailyRate                 1676 non-null   int64 \n",
      " 5   Department                1676 non-null   object\n",
      " 6   DistanceFromHome          1676 non-null   int64 \n",
      " 7   Education                 1676 non-null   int64 \n",
      " 8   EducationField            1676 non-null   object\n",
      " 9   EmployeeCount             1676 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1676 non-null   int64 \n",
      " 11  Gender                    1676 non-null   object\n",
      " 12  HourlyRate                1676 non-null   int64 \n",
      " 13  JobInvolvement            1676 non-null   int64 \n",
      " 14  JobLevel                  1676 non-null   int64 \n",
      " 15  JobRole                   1676 non-null   object\n",
      " 16  JobSatisfaction           1676 non-null   int64 \n",
      " 17  MaritalStatus             1676 non-null   object\n",
      " 18  MonthlyIncome             1676 non-null   int64 \n",
      " 19  MonthlyRate               1676 non-null   int64 \n",
      " 20  NumCompaniesWorked        1676 non-null   int64 \n",
      " 21  Over18                    1676 non-null   object\n",
      " 22  OverTime                  1676 non-null   object\n",
      " 23  PercentSalaryHike         1676 non-null   int64 \n",
      " 24  PerformanceRating         1676 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1676 non-null   int64 \n",
      " 26  StandardHours             1676 non-null   int64 \n",
      " 27  Shift                     1676 non-null   int64 \n",
      " 28  TotalWorkingYears         1676 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1676 non-null   int64 \n",
      " 30  WorkLifeBalance           1676 non-null   int64 \n",
      " 31  YearsAtCompany            1676 non-null   int64 \n",
      " 32  YearsInCurrentRole        1676 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1676 non-null   int64 \n",
      " 34  YearsWithCurrManager      1676 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 458.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 33)\n",
      "(1676,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 22.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SGDClassifier                      0.89               0.85     0.85      0.90   \n",
       "Perceptron                         0.90               0.83     0.83      0.90   \n",
       "PassiveAggressiveClassifier        0.90               0.80     0.80      0.90   \n",
       "LinearSVC                          0.91               0.78     0.78      0.91   \n",
       "NearestCentroid                    0.71               0.76     0.76      0.76   \n",
       "BernoulliNB                        0.90               0.76     0.76      0.90   \n",
       "LogisticRegression                 0.92               0.76     0.76      0.91   \n",
       "AdaBoostClassifier                 0.91               0.73     0.73      0.90   \n",
       "LinearDiscriminantAnalysis         0.90               0.72     0.72      0.89   \n",
       "XGBClassifier                      0.91               0.70     0.70      0.90   \n",
       "DecisionTreeClassifier             0.87               0.70     0.70      0.87   \n",
       "LGBMClassifier                     0.91               0.68     0.68      0.89   \n",
       "BaggingClassifier                  0.91               0.65     0.65      0.89   \n",
       "ExtraTreeClassifier                0.82               0.62     0.62      0.83   \n",
       "RandomForestClassifier             0.90               0.60     0.60      0.87   \n",
       "ExtraTreesClassifier               0.90               0.60     0.60      0.87   \n",
       "GaussianNB                         0.35               0.60     0.60      0.41   \n",
       "CalibratedClassifierCV             0.90               0.59     0.59      0.86   \n",
       "LabelSpreading                     0.85               0.58     0.58      0.84   \n",
       "LabelPropagation                   0.85               0.58     0.58      0.84   \n",
       "RidgeClassifier                    0.89               0.58     0.58      0.86   \n",
       "RidgeClassifierCV                  0.89               0.55     0.55      0.85   \n",
       "KNeighborsClassifier               0.88               0.53     0.53      0.84   \n",
       "SVC                                0.88               0.51     0.51      0.82   \n",
       "DummyClassifier                    0.88               0.50     0.50      0.82   \n",
       "QuadraticDiscriminantAnalysis      0.88               0.50     0.50      0.82   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SGDClassifier                        0.03  \n",
       "Perceptron                           0.03  \n",
       "PassiveAggressiveClassifier          0.03  \n",
       "LinearSVC                            0.03  \n",
       "NearestCentroid                      0.03  \n",
       "BernoulliNB                          0.02  \n",
       "LogisticRegression                   0.04  \n",
       "AdaBoostClassifier                   0.12  \n",
       "LinearDiscriminantAnalysis           0.03  \n",
       "XGBClassifier                        0.07  \n",
       "DecisionTreeClassifier               0.02  \n",
       "LGBMClassifier                       0.08  \n",
       "BaggingClassifier                    0.05  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "RandomForestClassifier               0.16  \n",
       "ExtraTreesClassifier                 0.12  \n",
       "GaussianNB                           0.02  \n",
       "CalibratedClassifierCV               0.05  \n",
       "LabelSpreading                       0.05  \n",
       "LabelPropagation                     0.05  \n",
       "RidgeClassifier                      0.02  \n",
       "RidgeClassifierCV                    0.02  \n",
       "KNeighborsClassifier                 0.10  \n",
       "SVC                                  0.04  \n",
       "DummyClassifier                      0.02  \n",
       "QuadraticDiscriminantAnalysis        0.03  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.8, random_state=42)\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "models, predictions = clf.fit(x_train,x_test,y_train,y_test)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeID                1676 non-null   int64 \n",
      " 1   Age                       1676 non-null   int64 \n",
      " 2   Attrition                 1676 non-null   int64 \n",
      " 3   BusinessTravel            1676 non-null   object\n",
      " 4   DailyRate                 1676 non-null   int64 \n",
      " 5   Department                1676 non-null   object\n",
      " 6   DistanceFromHome          1676 non-null   int64 \n",
      " 7   Education                 1676 non-null   int64 \n",
      " 8   EducationField            1676 non-null   object\n",
      " 9   EmployeeCount             1676 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1676 non-null   int64 \n",
      " 11  Gender                    1676 non-null   object\n",
      " 12  HourlyRate                1676 non-null   int64 \n",
      " 13  JobInvolvement            1676 non-null   int64 \n",
      " 14  JobLevel                  1676 non-null   int64 \n",
      " 15  JobRole                   1676 non-null   object\n",
      " 16  JobSatisfaction           1676 non-null   int64 \n",
      " 17  MaritalStatus             1676 non-null   object\n",
      " 18  MonthlyIncome             1676 non-null   int64 \n",
      " 19  MonthlyRate               1676 non-null   int64 \n",
      " 20  NumCompaniesWorked        1676 non-null   int64 \n",
      " 21  Over18                    1676 non-null   object\n",
      " 22  OverTime                  1676 non-null   object\n",
      " 23  PercentSalaryHike         1676 non-null   int64 \n",
      " 24  PerformanceRating         1676 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1676 non-null   int64 \n",
      " 26  StandardHours             1676 non-null   int64 \n",
      " 27  Shift                     1676 non-null   int64 \n",
      " 28  TotalWorkingYears         1676 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1676 non-null   int64 \n",
      " 30  WorkLifeBalance           1676 non-null   int64 \n",
      " 31  YearsAtCompany            1676 non-null   int64 \n",
      " 32  YearsInCurrentRole        1676 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1676 non-null   int64 \n",
      " 34  YearsWithCurrManager      1676 non-null   int64 \n",
      "dtypes: int64(27), object(8)\n",
      "memory usage: 458.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nurse</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel  Department EducationField  Gender JobRole MaritalStatus  \\\n",
       "0      Travel_Rarely  Cardiology  Life Sciences  Female   Nurse        Single   \n",
       "1  Travel_Frequently   Maternity  Life Sciences    Male   Other       Married   \n",
       "\n",
       "  Over18 OverTime  \n",
       "0      Y      Yes  \n",
       "1      Y       No  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(include=['object']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department:  ['Cardiology' 'Maternity' 'Neurology']\n",
      "Business Data:  ['Travel_Rarely' 'Travel_Frequently' 'Non-Travel']\n",
      "EducationField:  ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'\n",
      " 'Human Resources']\n",
      "Gender:  ['Female' 'Male']\n",
      "JobRole:  ['Nurse' 'Other' 'Therapist' 'Administrative' 'Admin']\n",
      "MaritalStatus\t:  ['Single' 'Married' 'Divorced']\n",
      "Over18:  ['Y']\n",
      "OverTime:  ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(\"Department: \", data.Department.unique())\n",
    "print(\"Business Data: \",data.BusinessTravel.unique())\n",
    "print(\"EducationField: \",data.EducationField.unique())\n",
    "print(\"Gender: \",data.Gender.unique())\n",
    "print(\"JobRole: \",data.JobRole.unique())\n",
    "print(\"MaritalStatus\t: \",data.MaritalStatus\t.unique())\n",
    "print(\"Over18: \",data.Over18.unique())\n",
    "print(\"OverTime: \", data.OverTime.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- Because we don't see many unique responses to any of these variables, *with Educational Field having the most with 6*, I am going to encode these variables in place rather than using get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script for parsing data for neural networks\n",
    "def convert_numeric(data):\n",
    "\n",
    "    convert_obj = {\"Department\" : {\"Cardiology\" : 1, \"Maternity\" : 2, \"Neurology\" : 3},\n",
    "                   \"BusinessTravel\" : {\"Travel_Rarely\" : 1, \"Travel_Frequently\" : 2, \"Non-Travel\" : 3},\n",
    "                   \"EducationField\" : {\"Life Sciences\" : 1, \"Other\" : 2, \"Medical\" : 3, \"Marketing\" : 4,\n",
    "                                        \"Technical Degree\" : 5, \"Human Resources\" : 6},\n",
    "                    \"Gender\" : {\"Female\" : 1, \"Male\" : 2},\n",
    "                    \"JobRole\" : {\"Nurse\" : 1, \"Other\" : 2, \"Therapist\" : 3, \"Administrative\" : 4, \"Admin\" : 5},\n",
    "                    \"MaritalStatus\" : {\"Single\" : 1, \"Married\" : 2, \"Divorced\" : 4},\n",
    "                    \"Over18\" : {\"Y\" : 1},\n",
    "                    \"OverTime\" : {\"Yes\" : 1, \"No\" : 0}\n",
    "        \n",
    "    }\n",
    "\n",
    "    data = data.replace(convert_obj)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_numeric(data)\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1671    1\n",
       "1672    0\n",
       "1673    0\n",
       "1674    0\n",
       "1675    0\n",
       "Name: Attrition, Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot accuracy and loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    \n",
    "    plt.figure(1)  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "\n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history.history['recall'])  \n",
    "    plt.plot(history.history['val_recall'])  \n",
    "    plt.title('RECALL')  \n",
    "    plt.ylabel('Recall ratio')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "    # summarize history for loss  \n",
    "\n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "670/670 - 2s - loss: 92412.6953 - recall: 0.8239 - val_loss: 54418.5938 - val_recall: 0.8601 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "670/670 - 1s - loss: 96690.3984 - recall: 0.8127 - val_loss: 100270.1172 - val_recall: 0.8601 - 749ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "670/670 - 1s - loss: 87760.1641 - recall: 0.8254 - val_loss: 82618.4609 - val_recall: 0.8601 - 725ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "670/670 - 1s - loss: 92260.4688 - recall: 0.8224 - val_loss: 100847.8438 - val_recall: 0.6131 - 738ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "670/670 - 1s - loss: 88146.4688 - recall: 0.8231 - val_loss: 171417.9688 - val_recall: 0.8601 - 703ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "670/670 - 1s - loss: 87892.5469 - recall: 0.8358 - val_loss: 164462.2031 - val_recall: 0.8601 - 689ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "670/670 - 1s - loss: 89483.8125 - recall: 0.8276 - val_loss: 163992.2344 - val_recall: 0.8601 - 748ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "670/670 - 1s - loss: 86034.0859 - recall: 0.8276 - val_loss: 54314.2305 - val_recall: 0.7173 - 699ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "670/670 - 1s - loss: 92692.1641 - recall: 0.8209 - val_loss: 593378.5000 - val_recall: 0.2292 - 716ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "670/670 - 1s - loss: 93842.5938 - recall: 0.8246 - val_loss: 74531.1875 - val_recall: 0.8601 - 704ms/epoch - 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 74531.1953 - recall: 0.8601\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74531.1953125, 0.8601190447807312]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# way to one hot encode the target variable into categorical variables\n",
    "y_train = keras.utils.to_categorical(y_train, len(np.unique(y)))\n",
    "y_val = keras.utils.to_categorical(y_val, len(np.unique(y)))\n",
    "\n",
    "\n",
    "# need to do [1:] to allow for dimensionality compatability\n",
    "a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "\n",
    "# if normalize:\n",
    "#     print('****** With Normalization Layer *******')\n",
    "#     b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "# look at keras.activations options\n",
    "# make sure to functionalize the layer object so we pass tensors\n",
    "b = keras.layers.Dense(y_train.shape[1], activation = keras.activations.softmax)(b)\n",
    "\n",
    "# utilizing stochasisity to help find the best hyper parameters will be quicker than iterating through\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "\n",
    "# engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "lr = .01\n",
    "\n",
    "\n",
    "# reset the model\n",
    "model = keras.Model(a,b)\n",
    "\n",
    "# Prep the model for -learning-\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "metrics=[keras.metrics.Recall(thresholds=0)])\n",
    "\n",
    "# urn off print because we will look at the best model\n",
    "history = model.fit(x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    verbose = 2,\n",
    "    validation_data = (x_val, y_val)\n",
    "            )\n",
    "# don't need to print out each evaluation\n",
    "score = model.evaluate(x_val, y_val, verbose = 1)\n",
    "\n",
    "plot_acc_loss(history)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes = True, expand_nested = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# way to one hot encode the target variable into categorical variables\n",
    "y_train = keras.utils.to_categorical(y_train, len(np.unique(y)))\n",
    "y_val = keras.utils.to_categorical(y_val, len(np.unique(y)))\n",
    "\n",
    "output = model.predict(x_val)\n",
    "\n",
    "print(output)\n",
    "\n",
    "# incorrect = np.where(np.argmax(output,axis=-1) != np.argmax(y_val, axis=-1))\n",
    "# correct = np.where(np.argmax(output,axis=-1) == np.argmax(y_val, axis=-1))\n",
    "# print(\"Accuracy of predictions: \",(np.size(correct) / (np.size(incorrect) + np.size(correct))))\n",
    "      \n",
    "# incorrect_spots = incorrect[0]  \n",
    "      \n",
    "# print('**********Wrong Predictions**********')\n",
    "# print('Number of wrong predictions: ', np.size(incorrect_spots))\n",
    "# for i in range(np.size(incorrect_spots)):\n",
    "#     print('Predicted class value at index', incorrect_spots[i], ': ', np.argmax(output[incorrect_spots[i]]))\n",
    "#     print('Actual class value at index', incorrect_spots[i], ': ',np.argmax(y_val[incorrect_spots[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_and_test_model(data, learning_rate_range_start, learning_rate_range_end, learning_rate_step\n",
    "                          , val_accuracy_thresh, batch_size_range_start\n",
    "                          , batch_size_range_end, batch_size_step, epoch_range_start\n",
    "                          , epoch_range_end, epoch_range_step, iter_size, max_score, min_loss\n",
    "                          , best_batch_size, best_num_epochs, best_lr, best_model, best_history, normalize = False):\n",
    "    \n",
    "    # take the data and split it into training and validation sets with proper encodings\n",
    "\n",
    "    y = data['Attrition']\n",
    "    x = data.drop(columns='Attrition')\n",
    "\n",
    "    y.replace('No', 0, inplace=True)\n",
    "    y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "    # initialize the counter for the iterations, and the list to store the data   \n",
    "    iteration = 0\n",
    "    data_list = []\n",
    "\n",
    "    # create loop to go through a large ranges of batch_size and epochs combinations to find the optimal combo\n",
    "    while (max_score < val_accuracy_thresh) and (iteration < iter_size):\n",
    "\n",
    "\n",
    "        # need to do [1:] to allow for dimensionality compatability\n",
    "        a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "        \n",
    "        if normalize:\n",
    "            print('****** With Normalization Layer *******')\n",
    "            b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "        # look at keras.activations options\n",
    "        # make sure to functionalize the layer object so we pass tensors\n",
    "        b = keras.layers.Dense(1, activation = keras.activations.softmax)(b)\n",
    "    \n",
    "        # utilizing stochasisity to help find the best hyper parameters will be quicker than iterating through\n",
    "        batch_size = rand.randrange(batch_size_range_start, batch_size_range_end, batch_size_step)\n",
    "        epochs = rand.randrange(epoch_range_start, epoch_range_end, epoch_range_step)\n",
    "\n",
    "        # engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "        lr = np.random.choice(np.arange(learning_rate_range_start, learning_rate_range_end, learning_rate_step), size=1)[0]\n",
    "        print(\"batch size : \", batch_size, \"...  epochs :\", epochs,\"... learning rate:\" , lr,\"...  iteration:\", iteration)\n",
    "\n",
    "        # reset the model\n",
    "        model = keras.Model(a,b)\n",
    "\n",
    "        # Prep the model for -learning-\n",
    "        model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "                metrics=keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "\n",
    "        # Train the model and record the training\n",
    "        # urn off print because we will look at the best model\n",
    "        history = model.fit(x_train, y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            verbose = 0,\n",
    "            validation_data = (x_val, y_val)\n",
    "                    )\n",
    "        # don't need to print out each evaluation\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        print(\"acc_score: \", score[1], \"loss_value: \", score[0])\n",
    "\n",
    "        if (score[1] > max_score):\n",
    "            max_score = score[1]\n",
    "            min_loss = score[0]\n",
    "            best_batch_size = batch_size\n",
    "            best_num_epochs = epochs\n",
    "            best_lr = lr\n",
    "            # make sure to use deepcopy so we get the object not a reference\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_history = copy.deepcopy(history)\n",
    "        \n",
    "        # increment the iteration\n",
    "        iteration += 1\n",
    "        \n",
    "        row = [score[1], score[0], batch_size, epochs, lr]\n",
    "        data_list.append(row)\n",
    "\n",
    "    # create the dataframe with the data_list\n",
    "    df = pd.DataFrame(data_list, columns=['score', 'loss', 'batch_size', 'epochs', 'learning_rate'])\n",
    "\n",
    "    return df, max_score, min_loss, best_batch_size, best_num_epochs, best_lr, best_model, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size :  8 ...  epochs : 100 ... learning rate: 0.009000000000000001 ...  iteration: 0\n",
      "acc_score:  1.0 loss_value:  2344827648.0\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 17:36:02         1894\n",
      "metadata.json                                  2023-02-16 17:36:02           64\n",
      "variables.h5                                   2023-02-16 17:36:02        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 17:36:02         1894\n",
      "metadata.json                                  2023-02-16 17:36:02           64\n",
      "variables.h5                                   2023-02-16 17:36:02        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 17:36:02         1894\n",
      "metadata.json                                  2023-02-16 17:36:02           64\n",
      "variables.h5                                   2023-02-16 17:36:02        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 17:36:02         1894\n",
      "metadata.json                                  2023-02-16 17:36:02           64\n",
      "variables.h5                                   2023-02-16 17:36:02        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "df, max_score, min_loss, best_batch_score, best_num_epochs, best_lr,best_model, best_history = create_and_test_model(data, 0.005, 0.011, 0.001, 0.90, 2, 20, 2, 50, 300, 25, 5, 0, 100, 0, 0, 0, None, None, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1000us/step\n",
      "Accuracy of predictions:  0.0\n",
      "**********Wrong Predictions**********\n",
      "Number of wrong predictions:  336\n",
      "Predicted class value at index 0 :  0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\EDA.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39msize(incorrect_spots)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X40sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPredicted class value at index\u001b[39m\u001b[39m'\u001b[39m, incorrect_spots[i], \u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39margmax(output[incorrect_spots[i]]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X40sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mActual class value at index\u001b[39m\u001b[39m'\u001b[39m, incorrect_spots[i], \u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m,np\u001b[39m.\u001b[39margmax(y_val[incorrect_spots[i]]))\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# show the locations where the predictions were wrong\n",
    "\n",
    "# Validate the results of the loop\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns='Attrition')\n",
    "\n",
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "\n",
    "output = best_model.predict(x_val)\n",
    "\n",
    "incorrect = np.where(np.argmax(output,axis=-1) != np.argmax(y_val, axis=-1))\n",
    "correct = np.where(np.argmax(output,axis=-1) == np.argmax(y_val, axis=-1))\n",
    "print(\"Accuracy of predictions: \",(np.size(correct) / (np.size(incorrect) + np.size(correct))))\n",
    "      \n",
    "incorrect_spots = incorrect[0]  \n",
    "      \n",
    "print('**********Wrong Predictions**********')\n",
    "print('Number of wrong predictions: ', np.size(incorrect_spots))\n",
    "for i in range(np.size(incorrect_spots)):\n",
    "    print('Predicted class value at index', incorrect_spots[i], ': ', np.argmax(output[incorrect_spots[i]]))\n",
    "    print('Actual class value at index', incorrect_spots[i], ': ',np.argmax(y_val[incorrect_spots[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'false_positives', 'val_loss', 'val_false_positives'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>Shift</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1239491</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1552398</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1364682</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1700476</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>735</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1187985</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1463621</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1347924</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1279649</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1626443</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1856176</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1059</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeID  Age  BusinessTravel  DailyRate  Department  \\\n",
       "1572     1239491   35               1        619           1   \n",
       "283      1552398   55               1        147           2   \n",
       "797      1364682   28               2       1009           2   \n",
       "1364     1700476   34               2        735           3   \n",
       "225      1187985   59               1        142           2   \n",
       "...          ...  ...             ...        ...         ...   \n",
       "1130     1463621   43               1        990           2   \n",
       "1294     1347924   26               1        920           3   \n",
       "860      1279649   33               1        147           3   \n",
       "1459     1626443   31               3        325           1   \n",
       "1126     1856176   42               1       1059           3   \n",
       "\n",
       "      DistanceFromHome  Education  EducationField  EmployeeCount  \\\n",
       "1572                 1          3               4              1   \n",
       "283                 20          2               5              1   \n",
       "797                  1          3               3              1   \n",
       "1364                22          4               2              1   \n",
       "225                  3          3               1              1   \n",
       "...                ...        ...             ...            ...   \n",
       "1130                27          3               5              1   \n",
       "1294                20          2               3              1   \n",
       "860                  2          3               6              1   \n",
       "1459                 5          3               3              1   \n",
       "1126                 9          2               2              1   \n",
       "\n",
       "      EnvironmentSatisfaction  ...  RelationshipSatisfaction  StandardHours  \\\n",
       "1572                        2  ...                         3             80   \n",
       "283                         2  ...                         4             80   \n",
       "797                         1  ...                         1             80   \n",
       "1364                        3  ...                         2             80   \n",
       "225                         3  ...                         1             80   \n",
       "...                       ...  ...                       ...            ...   \n",
       "1130                        4  ...                         3             80   \n",
       "1294                        4  ...                         3             80   \n",
       "860                         2  ...                         4             80   \n",
       "1459                        2  ...                         2             80   \n",
       "1126                        4  ...                         4             80   \n",
       "\n",
       "      Shift  TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "1572      0                 15                      2                3   \n",
       "283       1                 12                      4                3   \n",
       "797       2                  1                      2                3   \n",
       "1364      0                 16                      3                3   \n",
       "225       1                  7                      6                3   \n",
       "...     ...                ...                    ...              ...   \n",
       "1130      1                  8                      0                3   \n",
       "1294      0                  6                      3                3   \n",
       "860       1                  5                      2                3   \n",
       "1459      0                 10                      2                3   \n",
       "1126      0                 24                      2                3   \n",
       "\n",
       "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "1572              11                   9                        6   \n",
       "283               10                   7                        0   \n",
       "797                1                   0                        0   \n",
       "1364              15                  10                        6   \n",
       "225                1                   0                        0   \n",
       "...              ...                 ...                      ...   \n",
       "1130               6                   4                        0   \n",
       "1294               5                   1                        1   \n",
       "860                5                   4                        1   \n",
       "1459               9                   4                        1   \n",
       "1126               1                   0                        0   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "1572                     9  \n",
       "283                      8  \n",
       "797                      0  \n",
       "1364                    11  \n",
       "225                      0  \n",
       "...                    ...  \n",
       "1130                     2  \n",
       "1294                     4  \n",
       "860                      4  \n",
       "1459                     7  \n",
       "1126                     1  \n",
       "\n",
       "[335 rows x 34 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a74b6a200323c7ff9fb958487b2523ec46e5f6d52f4531a6be995daba14337f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
