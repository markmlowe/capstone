{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the propert libraries and load the dataset for modeling\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import copy\n",
    "import random as rand\n",
    "\n",
    "data = pd.read_csv(\"c:\\\\Users\\\\markm\\\\Desktop\\\\CAPSTONE\\\\capstone\\\\data\\\\external\\\\watson_healthcare_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the first 5 rows of data for familiarization\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .info() call to see the total number of rows, columns, and datatypes of columns.\n",
    "### Open the full output in a text editor if size limit is reached\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's slice the data into x and y, for building predictive models\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shape of the x and y dataframes to ensure they matchup\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the target variable to see if we have an imbalanced dataset\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case, we do have an imbalanced dataset because there are ~88% 'No's and ~12% 'Yes's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the target variable to quantitative for modeling purposes\n",
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms of each numerical value\n",
    "# This will look at variances within each individual feature, allowing us to eliminate features without variance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig = plt.figure(figsize = (20,12))\n",
    "x.hist(figsize = (24,20))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's look at some of the columns with the y value as well\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (20,10))\n",
    "\n",
    "\n",
    "ax[0].scatter(data.Education[data.Attrition==0], data.Age[data.Attrition==0], c='b', label = 'stayed')\n",
    "\n",
    "\n",
    "ax[1].scatter(data.Education[data.Attrition==1], data.Age[data.Attrition==1], c='r', label = 'attrited')\n",
    "\n",
    "\n",
    "ax[0].set_xlabel('Education Level')\n",
    "ax[0].set_ylabel('Age')\n",
    "ax[1].set_xlabel('Education Level')\n",
    "\n",
    "ax[0].set_title('Education level vs Age for Stayed', loc='center')\n",
    "ax[1].set_title('Education level vs Age for Attrition', loc='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Over18 column to see if there is variation in this feature\n",
    "x.Over18.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based off of this analysis, let's drop 'EmployeeCount' & 'StandardHours' because there is no variance in these features\n",
    "x = x.drop(columns=['Over18','EmployeeCount','StandardHours'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have initially analyzed the data, let's pass this data into 'LazyClassifier' to figure out which models could work best with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules \n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the x and y dataframes then call the LazyClassifier and display the results\n",
    "x_train_l, x_test_l, y_train_l, y_test_l = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "models, predictions = clf.fit(x_train_l,x_test_l,y_train_l,y_test_l)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the datatypes that are not quantitative\n",
    "data.select_dtypes(include=['object']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pint the unique values of each 'object' feature\n",
    "print(\"Department: \", data.Department.unique())\n",
    "print(\"Business Travel: \",data.BusinessTravel.unique())\n",
    "print(\"EducationField: \",data.EducationField.unique())\n",
    "print(\"Gender: \",data.Gender.unique())\n",
    "print(\"JobRole: \",data.JobRole.unique())\n",
    "print(\"MaritalStatus\t: \",data.MaritalStatus.unique())\n",
    "#print(\"Over18: \",data.Over18.unique())\n",
    "print(\"OverTime: \", data.OverTime.unique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- I am going to encode these variables using 'get_dummies' for modeling purposes, so that all pertinent variables are quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of the get_dummies call, including prefix for understanding of new variables\n",
    "pd.get_dummies(x['Department'], prefix='Department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function for converting the 'object' type features to quantitative features\n",
    "def convert_numeric(data):\n",
    "\n",
    "    # Get dummy variables for 'object' columns\n",
    "    data_ohe = data\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        col_ohe = pd.get_dummies(data[col], prefix=col)\n",
    "        data_ohe = pd.concat((data_ohe, col_ohe), axis=1).drop(col, axis=1)\n",
    "\n",
    "    return data_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data and show the first two rows of the new dataframe\n",
    "x = convert_numeric(x)\n",
    "\n",
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the names of the new columns\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method : Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model with unbalanced data (before using SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression  model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the base instance of the model for exploration, setting the max_iterations high so the model can reach convergence\n",
    "log_r = LogisticRegression(max_iter=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data after numeric conversion\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# fit the data on the training data\n",
    "log_r.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions and show the overall 'accuracy' of the model \n",
    "predictions = log_r.predict(x_test)\n",
    "score = log_r.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For better understanding of model performance, let's use a confusion matrix to show more in depth metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules for creating the confusion matric\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix and print the report\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try running the base model after balancing the data set to see if we have improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install imbalanced-learn\n",
    "# import imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "x_bal_train, y_bal_train = oversample.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the new re_sampled data, showcasing balance in the training data\n",
    "y_bal_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit the data on the balanced training data\n",
    "log_r.fit(x_bal_train, y_bal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for the model trained on 'balanced' training data and show accuracy\n",
    "predictions = log_r.predict(x_test)\n",
    "logr_score = log_r.score(x_test, y_test)\n",
    "print(logr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix of this 'balanced' log_r model and print the report for analysis\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(logr_score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall, the balancing of the data actually worsened our results by a little bit. For this reason, I will choose not to use SMOTE for the log_r model\n",
    "- Also, using SMOTE could cause explainability issues as it is a more complex technique. Therefore, keeping the data 'unbalanced' will allow for easier understanding of the model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create and test our XGBoost Classifier model\n",
    "import xgboost as xgb\n",
    "\n",
    "# create model instances for both 'unbalanced' and 'balanced' training data\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "xgb_bal_cl = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data after numeric conversion\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# transform the dataset using SMOTE \n",
    "oversample = SMOTE()\n",
    "x_bal_train, y_bal_train = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Fit the unbalanced model\n",
    "xgb_cl.fit(x_train, y_train)\n",
    "\n",
    "# Fit the 'balanced' model\n",
    "xgb_bal_cl.fit(x_bal_train, y_bal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the 'unbalanced' model and show the overall accuracy\n",
    "preds = xgb_cl.predict(x_test)\n",
    "\n",
    "xgb_score = xgb_cl.score(x_test, y_test)\n",
    "print(xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(xgb_score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the 'balanced' model and show the overall accuracy\n",
    "preds_bal = xgb_bal_cl.predict(x_test)\n",
    "\n",
    "xgb_bal_score = xgb_bal_cl.score(x_test, y_test)\n",
    "print(xgb_bal_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, preds_bal)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(xgb_bal_score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "print(classification_report(y_test,preds_bal))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For XGBOOST, I will use the 'balanced' model. Even though it's overall accuracy was slightly worse, It did have a lower false-negative number. This number is what I am trying to minimize (without having too much of a tradeoff in model performance), so the improvement in this category [Bottom left number where we predicted 'No' and it was actually 'Yes'] is worth the 1% loss in accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIRD MODEL : Neural Network\n",
    "- I will not be using this model in the actual 'run.py'. This attempt is just for fun to see if a 'simple' neural network could outperform logisitic regression / xgboost classifier\n",
    "\n",
    "- Even though I kept this network very simple, it did take a lot longer to train than the other models. Adding in parameters / better architecture to try to improve performance would only add to the computation time to train the network, so I am not going to be pursuin this model type to solve the attrition problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom loss for unbalanced data set using inverse weights\n",
    "\n",
    "class CrossEntropyLoss(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__(name='CrossEntropyLoss')\n",
    "\n",
    " \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Cross entropy loss adjusted for class imabalance and one-hot encoding sparsity\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "\n",
    "        loss = (tf.math.log(y_pred+epsilon)*y_true + tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "\n",
    "        tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "\n",
    "        return tf.reduce_sum(tf.reduce_mean(loss, axis = 0))\n",
    "\n",
    " \n",
    "\n",
    "class ClassImbalanceSparsityAdjustedCEL(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, inverse_class_weights):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Initialization of inverse class weights\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(name='ClassImbalanceSparsityAdjustedCEL')\n",
    "\n",
    "        self.inverse_class_weights = inverse_class_weights\n",
    "\n",
    " \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Cross entropy loss adjusted for class imabalance and one-hot encoding sparsity\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        P = tf.reduce_sum(y_true)\n",
    "\n",
    "        N = -1 * tf.reduce_sum(y_true - 1)\n",
    "\n",
    " \n",
    "\n",
    "        beta_P = tf.cast((P + N) / P, dtype=tf.float64)\n",
    "\n",
    "        beta_N = tf.cast((P + N) / N, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "\n",
    "        loss = (beta_P*tf.math.log(y_pred+epsilon)*y_true + beta_N*tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "\n",
    "        tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "\n",
    "        return tf.reduce_sum(tf.reduce_mean(loss, axis = 0)*self.inverse_class_weights)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot accuracy and loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    \n",
    "    plt.figure(1)  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "\n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history.history['precision'])  \n",
    "    plt.plot(history.history['val_precision'])  \n",
    "    plt.title('PRECISION')  \n",
    "    plt.ylabel('Precision ratio')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "    # summarize history for loss  \n",
    "\n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# set the paramters for the network\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_hidden_units = 128\n",
    "n_hidden_layers = 6\n",
    "\n",
    "# engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "lr = .002\n",
    "\n",
    "# way to one hot encode the target variable into categorical variables\n",
    "y_train = keras.utils.to_categorical(y_bal_train, len(np.unique(y)))\n",
    "y_val = keras.utils.to_categorical(y_test, len(np.unique(y)))\n",
    "\n",
    "\n",
    "# need to do [1:] to allow for dimensionality compatability\n",
    "a = b = keras.layers.Input(shape = x_bal_train.shape[1:])\n",
    "\n",
    "print('****** With Normalization Layer *******')\n",
    "a = keras.layers.LayerNormalization(axis= -1)(a)\n",
    "\n",
    "a = keras.layers.Flatten()(a)\n",
    "\n",
    "\n",
    "print('Residual True')\n",
    "a = keras.layers.Dense(n_hidden_units)(a)\n",
    "for _ in range(n_hidden_layers):\n",
    "    a_resid = a\n",
    "    a = keras.layers.Dense(n_hidden_units, activation=keras.activations.relu)(a)\n",
    "    a = keras.layers.Add()([a, a_resid])\n",
    "\n",
    "# look at keras.activations options\n",
    "# make sure to functionalize the layer object so we pass tensors\n",
    "a = keras.layers.Dense(y_train.shape[1], activation = keras.activations.softmax)(a)\n",
    "\n",
    "# reset the model\n",
    "model = keras.Model(b,a)\n",
    "\n",
    "# Prep the model for -learning-\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "optimizer='adam',\n",
    "metrics=[keras.metrics.Precision(thresholds=0)])\n",
    "\n",
    "# urn off print because we will look at the best model\n",
    "history = model.fit(x_bal_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    verbose = 2,\n",
    "    validation_data = (x_test, y_val)\n",
    "            )\n",
    "# don't need to print out each evaluation\n",
    "score = model.evaluate(x_test, y_val, verbose = 1)\n",
    "\n",
    "plot_acc_loss(history)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "threshold = 0.45\n",
    "\n",
    "\n",
    "output = model.predict(np.asarray(x_test).astype('float32'))\n",
    "\n",
    "output[output[:,1] > threshold] = [0,1]\n",
    "\n",
    "\n",
    "actual = np.argmax(y_val, axis=-1)\n",
    "predicted = np.argmax(output, axis=-1)\n",
    "\n",
    "incorrect = np.where(np.argmax(output,axis=-1) != np.argmax(y_val, axis=-1))\n",
    "correct = np.where(np.argmax(output,axis=-1) == np.argmax(y_val, axis=-1))\n",
    "print(\"Accuracy of predictions: \",round((np.size(correct) / (np.size(incorrect) + np.size(correct))) * 100,2))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_and_test_model(data, learning_rate_range_start, learning_rate_range_end, learning_rate_step\n",
    "                          , val_accuracy_thresh, batch_size_range_start\n",
    "                          , batch_size_range_end, batch_size_step, epoch_range_start\n",
    "                          , epoch_range_end, epoch_range_step, iter_size, max_score, min_loss\n",
    "                          , best_batch_size, best_num_epochs, best_lr, best_model, best_history, normalize = False):\n",
    "    \n",
    "    # take the data and split it into training and validation sets with proper encodings\n",
    "\n",
    "    y = data['Attrition']\n",
    "    x = data.drop(columns='Attrition')\n",
    "\n",
    "    y.replace('No', 0, inplace=True)\n",
    "    y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "    # initialize the counter for the iterations, and the list to store the data   \n",
    "    iteration = 0\n",
    "    data_list = []\n",
    "\n",
    "    # create loop to go through a large ranges of batch_size and epochs combinations to find the optimal combo\n",
    "    while (max_score < val_accuracy_thresh) and (iteration < iter_size):\n",
    "\n",
    "\n",
    "        # need to do [1:] to allow for dimensionality compatability\n",
    "        a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "        \n",
    "        if normalize:\n",
    "            print('****** With Normalization Layer *******')\n",
    "            b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "        # look at keras.activations options\n",
    "        # make sure to functionalize the layer object so we pass tensors\n",
    "        b = keras.layers.Dense(1, activation = keras.activations.softmax)(b)\n",
    "    \n",
    "        # utilizing stochasisity to help find the best hyper parameters will be quicker than iterating through\n",
    "        batch_size = rand.randrange(batch_size_range_start, batch_size_range_end, batch_size_step)\n",
    "        epochs = rand.randrange(epoch_range_start, epoch_range_end, epoch_range_step)\n",
    "\n",
    "        # engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "        lr = np.random.choice(np.arange(learning_rate_range_start, learning_rate_range_end, learning_rate_step), size=1)[0]\n",
    "        print(\"batch size : \", batch_size, \"...  epochs :\", epochs,\"... learning rate:\" , lr,\"...  iteration:\", iteration)\n",
    "\n",
    "        # reset the model\n",
    "        model = keras.Model(a,b)\n",
    "\n",
    "        # Prep the model for -learning-\n",
    "        model.compile(loss=keras.losses.BinaryCrossentropy(log_ints=True),\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "        metrics=[keras.metrics.Recall(thresholds=0)])\n",
    "\n",
    "        # urn off print because we will look at the best model\n",
    "        history = model.fit(x_train, y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            verbose = 2,\n",
    "            validation_data = (x_val, y_val)\n",
    "            )\n",
    "        # don't need to print out each evaluation\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        print(\"acc_score: \", score[1], \"loss_value: \", score[0])\n",
    "\n",
    "        if (score[1] > max_score):\n",
    "            max_score = score[1]\n",
    "            min_loss = score[0]\n",
    "            best_batch_size = batch_size\n",
    "            best_num_epochs = epochs\n",
    "            best_lr = lr\n",
    "            # make sure to use deepcopy so we get the object not a reference\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_history = copy.deepcopy(history)\n",
    "        \n",
    "        # increment the iteration\n",
    "        iteration += 1\n",
    "        \n",
    "        row = [score[1], score[0], batch_size, epochs, lr]\n",
    "        data_list.append(row)\n",
    "\n",
    "    # create the dataframe with the data_list\n",
    "    df = pd.DataFrame(data_list, columns=['score', 'loss', 'batch_size', 'epochs', 'learning_rate'])\n",
    "\n",
    "    return df, max_score, min_loss, best_batch_size, best_num_epochs, best_lr, best_model, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df, max_score, min_loss, best_batch_score, best_num_epochs, best_lr,best_model, best_history = create_and_test_model(data, 0.005, 0.011, 0.001, 0.90, 2, 20, 2, 50, 300, 25, 5, 0, 100, 0, 0, 0, None, None, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a74b6a200323c7ff9fb958487b2523ec46e5f6d52f4531a6be995daba14337f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
