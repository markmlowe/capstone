{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import copy\n",
    "import random as rand\n",
    "\n",
    "data = pd.read_csv(\"c:\\\\Users\\\\markm\\\\Desktop\\\\CAPSTONE\\\\capstone\\\\data\\\\external\\\\watson_healthcare_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>Shift</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313919</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200302</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060315</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272912</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1414939</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  Age Attrition     BusinessTravel  DailyRate  Department  \\\n",
       "0     1313919   41        No      Travel_Rarely       1102  Cardiology   \n",
       "1     1200302   49        No  Travel_Frequently        279   Maternity   \n",
       "2     1060315   37       Yes      Travel_Rarely       1373   Maternity   \n",
       "3     1272912   33        No  Travel_Frequently       1392   Maternity   \n",
       "4     1414939   27        No      Travel_Rarely        591   Maternity   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  ...  \\\n",
       "0                 1          2  Life Sciences              1  ...   \n",
       "1                 8          1  Life Sciences              1  ...   \n",
       "2                 2          2          Other              1  ...   \n",
       "3                 3          4  Life Sciences              1  ...   \n",
       "4                 2          1        Medical              1  ...   \n",
       "\n",
       "   RelationshipSatisfaction StandardHours  Shift  TotalWorkingYears  \\\n",
       "0                         1            80      0                  8   \n",
       "1                         4            80      1                 10   \n",
       "2                         2            80      0                  7   \n",
       "3                         3            80      0                  8   \n",
       "4                         4            80      1                  6   \n",
       "\n",
       "   TrainingTimesLastYear WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                      0               1               6                  4   \n",
       "1                      3               3              10                  7   \n",
       "2                      3               3               0                  0   \n",
       "3                      3               3               8                  7   \n",
       "4                      3               3               2                  2   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                     5  \n",
       "1                        1                     7  \n",
       "2                        0                     0  \n",
       "3                        3                     0  \n",
       "4                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeID                1676 non-null   int64 \n",
      " 1   Age                       1676 non-null   int64 \n",
      " 2   Attrition                 1676 non-null   object\n",
      " 3   BusinessTravel            1676 non-null   object\n",
      " 4   DailyRate                 1676 non-null   int64 \n",
      " 5   Department                1676 non-null   object\n",
      " 6   DistanceFromHome          1676 non-null   int64 \n",
      " 7   Education                 1676 non-null   int64 \n",
      " 8   EducationField            1676 non-null   object\n",
      " 9   EmployeeCount             1676 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1676 non-null   int64 \n",
      " 11  Gender                    1676 non-null   object\n",
      " 12  HourlyRate                1676 non-null   int64 \n",
      " 13  JobInvolvement            1676 non-null   int64 \n",
      " 14  JobLevel                  1676 non-null   int64 \n",
      " 15  JobRole                   1676 non-null   object\n",
      " 16  JobSatisfaction           1676 non-null   int64 \n",
      " 17  MaritalStatus             1676 non-null   object\n",
      " 18  MonthlyIncome             1676 non-null   int64 \n",
      " 19  MonthlyRate               1676 non-null   int64 \n",
      " 20  NumCompaniesWorked        1676 non-null   int64 \n",
      " 21  Over18                    1676 non-null   object\n",
      " 22  OverTime                  1676 non-null   object\n",
      " 23  PercentSalaryHike         1676 non-null   int64 \n",
      " 24  PerformanceRating         1676 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1676 non-null   int64 \n",
      " 26  StandardHours             1676 non-null   int64 \n",
      " 27  Shift                     1676 non-null   int64 \n",
      " 28  TotalWorkingYears         1676 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1676 non-null   int64 \n",
      " 30  WorkLifeBalance           1676 non-null   int64 \n",
      " 31  YearsAtCompany            1676 non-null   int64 \n",
      " 32  YearsInCurrentRole        1676 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1676 non-null   int64 \n",
      " 34  YearsWithCurrManager      1676 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 458.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 33)\n",
      "(1676,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1477\n",
       "Yes     199\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 11.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SGDClassifier                      0.91               0.79     0.79      0.91   \n",
       "LinearSVC                          0.92               0.79     0.79      0.92   \n",
       "LogisticRegression                 0.92               0.78     0.78      0.92   \n",
       "PassiveAggressiveClassifier        0.89               0.78     0.78      0.89   \n",
       "AdaBoostClassifier                 0.93               0.77     0.77      0.92   \n",
       "Perceptron                         0.90               0.76     0.76      0.90   \n",
       "NearestCentroid                    0.71               0.74     0.74      0.75   \n",
       "CalibratedClassifierCV             0.92               0.74     0.74      0.91   \n",
       "LinearDiscriminantAnalysis         0.91               0.73     0.73      0.90   \n",
       "BernoulliNB                        0.86               0.73     0.73      0.87   \n",
       "XGBClassifier                      0.91               0.71     0.71      0.90   \n",
       "DecisionTreeClassifier             0.89               0.71     0.71      0.88   \n",
       "LGBMClassifier                     0.90               0.70     0.70      0.89   \n",
       "ExtraTreesClassifier               0.90               0.68     0.68      0.88   \n",
       "ExtraTreeClassifier                0.87               0.67     0.67      0.86   \n",
       "RandomForestClassifier             0.90               0.67     0.67      0.88   \n",
       "SVC                                0.90               0.66     0.66      0.88   \n",
       "LabelSpreading                     0.85               0.65     0.65      0.85   \n",
       "LabelPropagation                   0.85               0.65     0.65      0.85   \n",
       "BaggingClassifier                  0.89               0.64     0.64      0.87   \n",
       "GaussianNB                         0.40               0.61     0.61      0.46   \n",
       "QuadraticDiscriminantAnalysis      0.44               0.60     0.60      0.51   \n",
       "RidgeClassifier                    0.89               0.60     0.60      0.85   \n",
       "RidgeClassifierCV                  0.88               0.59     0.59      0.85   \n",
       "KNeighborsClassifier               0.88               0.58     0.58      0.84   \n",
       "DummyClassifier                    0.86               0.50     0.50      0.80   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SGDClassifier                        0.04  \n",
       "LinearSVC                            0.08  \n",
       "LogisticRegression                   0.06  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "AdaBoostClassifier                   0.21  \n",
       "Perceptron                           0.02  \n",
       "NearestCentroid                      0.06  \n",
       "CalibratedClassifierCV               0.19  \n",
       "LinearDiscriminantAnalysis           0.03  \n",
       "BernoulliNB                          0.03  \n",
       "XGBClassifier                        0.21  \n",
       "DecisionTreeClassifier               0.03  \n",
       "LGBMClassifier                       0.12  \n",
       "ExtraTreesClassifier                 0.24  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "RandomForestClassifier               0.34  \n",
       "SVC                                  0.09  \n",
       "LabelSpreading                       0.19  \n",
       "LabelPropagation                     0.17  \n",
       "BaggingClassifier                    0.13  \n",
       "GaussianNB                           0.03  \n",
       "QuadraticDiscriminantAnalysis        0.03  \n",
       "RidgeClassifier                      0.03  \n",
       "RidgeClassifierCV                    0.03  \n",
       "KNeighborsClassifier                 0.09  \n",
       "DummyClassifier                      0.02  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "models, predictions = clf.fit(x_train,x_test,y_train,y_test)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nurse</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel  Department EducationField  Gender JobRole MaritalStatus  \\\n",
       "0      Travel_Rarely  Cardiology  Life Sciences  Female   Nurse        Single   \n",
       "1  Travel_Frequently   Maternity  Life Sciences    Male   Other       Married   \n",
       "\n",
       "  Over18 OverTime  \n",
       "0      Y      Yes  \n",
       "1      Y       No  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(include=['object']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department:  ['Cardiology' 'Maternity' 'Neurology']\n",
      "Business Data:  ['Travel_Rarely' 'Travel_Frequently' 'Non-Travel']\n",
      "EducationField:  ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'\n",
      " 'Human Resources']\n",
      "Gender:  ['Female' 'Male']\n",
      "JobRole:  ['Nurse' 'Other' 'Therapist' 'Administrative' 'Admin']\n",
      "MaritalStatus\t:  ['Single' 'Married' 'Divorced']\n",
      "Over18:  ['Y']\n",
      "OverTime:  ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(\"Department: \", data.Department.unique())\n",
    "print(\"Business Data: \",data.BusinessTravel.unique())\n",
    "print(\"EducationField: \",data.EducationField.unique())\n",
    "print(\"Gender: \",data.Gender.unique())\n",
    "print(\"JobRole: \",data.JobRole.unique())\n",
    "print(\"MaritalStatus\t: \",data.MaritalStatus\t.unique())\n",
    "print(\"Over18: \",data.Over18.unique())\n",
    "print(\"OverTime: \", data.OverTime.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- Because we don't see many unique responses to any of these variables, *with Educational Field having the most with 6*, I am going to encode these variables in place rather than using get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script for parsing data for neural networks\n",
    "def convert_numeric(data):\n",
    "\n",
    "    convert_obj = {\"Department\" : {\"Cardiology\" : 1, \"Maternity\" : 2, \"Neurology\" : 3},\n",
    "                   \"BusinessTravel\" : {\"Travel_Rarely\" : 1, \"Travel_Frequently\" : 2, \"Non-Travel\" : 3},\n",
    "                   \"EducationField\" : {\"Life Sciences\" : 1, \"Other\" : 2, \"Medical\" : 3, \"Marketing\" : 4,\n",
    "                                        \"Technical Degree\" : 5, \"Human Resources\" : 6},\n",
    "                    \"Gender\" : {\"Female\" : 1, \"Male\" : 2},\n",
    "                    \"JobRole\" : {\"Nurse\" : 1, \"Other\" : 2, \"Therapist\" : 3, \"Administrative\" : 4, \"Admin\" : 5},\n",
    "                    \"MaritalStatus\" : {\"Single\" : 1, \"Married\" : 2, \"Divorced\" : 4},\n",
    "                    \"Over18\" : {\"Y\" : 1},\n",
    "                    \"OverTime\" : {\"Yes\" : 1, \"No\" : 0}\n",
    "        \n",
    "    }\n",
    "\n",
    "    data = data.replace(convert_obj)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_numeric(data)\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method : Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model with unbalanced target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression  model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the base instance of the model for exploration\n",
    "log_r = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data after numeric conversion\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# fit the data on the training data\n",
    "log_r.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660714285714286\n"
     ]
    }
   ],
   "source": [
    "predictions = log_r.predict(x_test)\n",
    "score = log_r.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       289\n",
      "           1       0.60      0.13      0.21        47\n",
      "\n",
      "    accuracy                           0.87       336\n",
      "   macro avg       0.74      0.56      0.57       336\n",
      "weighted avg       0.84      0.87      0.83       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15);\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try running the base model after balancing the data set to see if we have improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn\n",
    "import imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "x_bal_train, y_bal_train = oversample.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit the data on the balanced training data\n",
    "log_r.fit(x_bal_train, y_bal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7202380952380952\n"
     ]
    }
   ],
   "source": [
    "predictions = log_r.predict(x_test)\n",
    "score = log_r.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82       289\n",
      "           1       0.27      0.60      0.37        47\n",
      "\n",
      "    accuracy                           0.72       336\n",
      "   macro avg       0.60      0.67      0.60       336\n",
      "weighted avg       0.83      0.72      0.76       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {:.2f}%'.format(score*100, {\"3f\"})\n",
    "plt.title(all_sample_title, size = 15);\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom loss for unbalanced data set using inverse weights\n",
    "\n",
    "class CrossEntropyLoss(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__(name='CrossEntropyLoss')\n",
    "\n",
    " \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Cross entropy loss adjusted for class imabalance and one-hot encoding sparsity\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "\n",
    "        loss = (tf.math.log(y_pred+epsilon)*y_true + tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "\n",
    "        tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "\n",
    "        return tf.reduce_sum(tf.reduce_mean(loss, axis = 0))\n",
    "\n",
    " \n",
    "\n",
    "class ClassImbalanceSparsityAdjustedCEL(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, inverse_class_weights):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Initialization of inverse class weights\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(name='ClassImbalanceSparsityAdjustedCEL')\n",
    "\n",
    "        self.inverse_class_weights = inverse_class_weights\n",
    "\n",
    " \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Cross entropy loss adjusted for class imabalance and one-hot encoding sparsity\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        P = tf.reduce_sum(y_true)\n",
    "\n",
    "        N = -1 * tf.reduce_sum(y_true - 1)\n",
    "\n",
    " \n",
    "\n",
    "        beta_P = tf.cast((P + N) / P, dtype=tf.float64)\n",
    "\n",
    "        beta_N = tf.cast((P + N) / N, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    " \n",
    "\n",
    "        epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "\n",
    "        loss = (beta_P*tf.math.log(y_pred+epsilon)*y_true + beta_N*tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "\n",
    "        tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "\n",
    "        return tf.reduce_sum(tf.reduce_mean(loss, axis = 0)*self.inverse_class_weights)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1477\n",
       "1     199\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot accuracy and loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    \n",
    "    plt.figure(1)  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "\n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history.history['recall'])  \n",
    "    plt.plot(history.history['val_recall'])  \n",
    "    plt.title('RECALL')  \n",
    "    plt.ylabel('Recall ratio')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "    # summarize history for loss  \n",
    "\n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** With Normalization Layer *******\n",
      "Epoch 1/200\n",
      "42/42 - 4s - loss: 1.0657 - precision: 0.5000 - val_loss: 0.8143 - val_precision: 0.5000 - 4s/epoch - 95ms/step\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.6719 - precision: 0.5000 - val_loss: 0.5527 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.4746 - precision: 0.5000 - val_loss: 0.4457 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.3922 - precision: 0.5000 - val_loss: 0.4080 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.3607 - precision: 0.5000 - val_loss: 0.3978 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.3496 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.3451 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.3437 - precision: 0.5000 - val_loss: 0.3981 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.3428 - precision: 0.5000 - val_loss: 0.3983 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.3423 - precision: 0.5000 - val_loss: 0.3982 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.3419 - precision: 0.5000 - val_loss: 0.3985 - val_precision: 0.5000 - 100ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.3415 - precision: 0.5000 - val_loss: 0.3982 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.3411 - precision: 0.5000 - val_loss: 0.3983 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.3411 - precision: 0.5000 - val_loss: 0.3971 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.3402 - precision: 0.5000 - val_loss: 0.3975 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.3398 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.3395 - precision: 0.5000 - val_loss: 0.3964 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.3390 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.3385 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.3380 - precision: 0.5000 - val_loss: 0.3952 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.3377 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.3373 - precision: 0.5000 - val_loss: 0.3944 - val_precision: 0.5000 - 99ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.3366 - precision: 0.5000 - val_loss: 0.3951 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.3363 - precision: 0.5000 - val_loss: 0.3950 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.3359 - precision: 0.5000 - val_loss: 0.3936 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.3354 - precision: 0.5000 - val_loss: 0.3951 - val_precision: 0.5000 - 101ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.3351 - precision: 0.5000 - val_loss: 0.3933 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.3348 - precision: 0.5000 - val_loss: 0.3942 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.3346 - precision: 0.5000 - val_loss: 0.3934 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.3337 - precision: 0.5000 - val_loss: 0.3926 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.3333 - precision: 0.5000 - val_loss: 0.3934 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.3330 - precision: 0.5000 - val_loss: 0.3925 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.3326 - precision: 0.5000 - val_loss: 0.3925 - val_precision: 0.5000 - 87ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.3321 - precision: 0.5000 - val_loss: 0.3920 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.3317 - precision: 0.5000 - val_loss: 0.3929 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.3314 - precision: 0.5000 - val_loss: 0.3923 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.3313 - precision: 0.5000 - val_loss: 0.3924 - val_precision: 0.5000 - 105ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.3312 - precision: 0.5000 - val_loss: 0.3922 - val_precision: 0.5000 - 113ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.3304 - precision: 0.5000 - val_loss: 0.3928 - val_precision: 0.5000 - 112ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.3306 - precision: 0.5000 - val_loss: 0.3906 - val_precision: 0.5000 - 154ms/epoch - 4ms/step\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.3312 - precision: 0.5000 - val_loss: 0.3920 - val_precision: 0.5000 - 111ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.3298 - precision: 0.5000 - val_loss: 0.3914 - val_precision: 0.5000 - 109ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.3296 - precision: 0.5000 - val_loss: 0.3920 - val_precision: 0.5000 - 115ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.3293 - precision: 0.5000 - val_loss: 0.3923 - val_precision: 0.5000 - 99ms/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.3288 - precision: 0.5000 - val_loss: 0.3910 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.3286 - precision: 0.5000 - val_loss: 0.3919 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.3282 - precision: 0.5000 - val_loss: 0.3908 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.3281 - precision: 0.5000 - val_loss: 0.3912 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.3276 - precision: 0.5000 - val_loss: 0.3924 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.3279 - precision: 0.5000 - val_loss: 0.3912 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.3273 - precision: 0.5000 - val_loss: 0.3941 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.3273 - precision: 0.5000 - val_loss: 0.3916 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.3270 - precision: 0.5000 - val_loss: 0.3921 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.3268 - precision: 0.5000 - val_loss: 0.3919 - val_precision: 0.5000 - 100ms/epoch - 2ms/step\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.3267 - precision: 0.5000 - val_loss: 0.3926 - val_precision: 0.5000 - 108ms/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.3266 - precision: 0.5000 - val_loss: 0.3919 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.3267 - precision: 0.5000 - val_loss: 0.3928 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.3264 - precision: 0.5000 - val_loss: 0.3918 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.3266 - precision: 0.5000 - val_loss: 0.3927 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.3265 - precision: 0.5000 - val_loss: 0.3921 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.3261 - precision: 0.5000 - val_loss: 0.3938 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.3261 - precision: 0.5000 - val_loss: 0.3935 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.3262 - precision: 0.5000 - val_loss: 0.3928 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.3258 - precision: 0.5000 - val_loss: 0.3928 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.3257 - precision: 0.5000 - val_loss: 0.3930 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.3256 - precision: 0.5000 - val_loss: 0.3934 - val_precision: 0.5000 - 109ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.3259 - precision: 0.5000 - val_loss: 0.3931 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.3257 - precision: 0.5000 - val_loss: 0.3933 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.3255 - precision: 0.5000 - val_loss: 0.3938 - val_precision: 0.5000 - 87ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.3256 - precision: 0.5000 - val_loss: 0.3931 - val_precision: 0.5000 - 101ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.3256 - precision: 0.5000 - val_loss: 0.3939 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.3256 - precision: 0.5000 - val_loss: 0.3925 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3942 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.3255 - precision: 0.5000 - val_loss: 0.3935 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3936 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3940 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3944 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3929 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.3254 - precision: 0.5000 - val_loss: 0.3937 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3953 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3957 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3946 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3956 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3949 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 88ms/epoch - 2ms/step\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3937 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3956 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.3257 - precision: 0.5000 - val_loss: 0.3977 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3971 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3947 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3951 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3965 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.3256 - precision: 0.5000 - val_loss: 0.3981 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3959 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3969 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3959 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3976 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3964 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 87ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3978 - val_precision: 0.5000 - 88ms/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 88ms/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 136ms/epoch - 3ms/step\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3973 - val_precision: 0.5000 - 99ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3967 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3983 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3955 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3969 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3964 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3986 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3957 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3982 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.3252 - precision: 0.5000 - val_loss: 0.3983 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3977 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3977 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 101ms/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3970 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3965 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3967 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3970 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.3258 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3957 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3985 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3985 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3973 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3975 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3956 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3965 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3989 - val_precision: 0.5000 - 129ms/epoch - 3ms/step\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3973 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 112ms/epoch - 3ms/step\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3959 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3962 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3962 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3969 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3970 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3976 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3973 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3962 - val_precision: 0.5000 - 106ms/epoch - 3ms/step\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3961 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3967 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3977 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3975 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3953 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3973 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.3242 - precision: 0.5000 - val_loss: 0.3981 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3967 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.3242 - precision: 0.5000 - val_loss: 0.3962 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.3242 - precision: 0.5000 - val_loss: 0.3974 - val_precision: 0.5000 - 100ms/epoch - 2ms/step\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.3242 - precision: 0.5000 - val_loss: 0.3970 - val_precision: 0.5000 - 98ms/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3964 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.3245 - precision: 0.5000 - val_loss: 0.3983 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3974 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3959 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.3253 - precision: 0.5000 - val_loss: 0.3980 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3975 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.3242 - precision: 0.5000 - val_loss: 0.3974 - val_precision: 0.5000 - 97ms/epoch - 2ms/step\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.3249 - precision: 0.5000 - val_loss: 0.3958 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3991 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3991 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3955 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.3248 - precision: 0.5000 - val_loss: 0.3970 - val_precision: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3967 - val_precision: 0.5000 - 136ms/epoch - 3ms/step\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3975 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3963 - val_precision: 0.5000 - 90ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.3250 - precision: 0.5000 - val_loss: 0.3974 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3954 - val_precision: 0.5000 - 94ms/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3980 - val_precision: 0.5000 - 95ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.3244 - precision: 0.5000 - val_loss: 0.3981 - val_precision: 0.5000 - 93ms/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.3247 - precision: 0.5000 - val_loss: 0.3966 - val_precision: 0.5000 - 92ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.3251 - precision: 0.5000 - val_loss: 0.3968 - val_precision: 0.5000 - 96ms/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.3246 - precision: 0.5000 - val_loss: 0.3960 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.3243 - precision: 0.5000 - val_loss: 0.3992 - val_precision: 0.5000 - 91ms/epoch - 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3992 - precision: 0.5000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'recall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\01_mml_initial_data_exploration.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# don't need to print out each evaluation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_val, y_val, verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m plot_acc_loss(history)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(score)\n",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\01_mml_initial_data_exploration.ipynb Cell 33\u001b[0m in \u001b[0;36mplot_acc_loss\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# summarize history for accuracy  \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m211\u001b[39m)  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m'\u001b[39;49m])  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_recall\u001b[39m\u001b[39m'\u001b[39m])  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mRECALL\u001b[39m\u001b[39m'\u001b[39m)  \n",
      "\u001b[1;31mKeyError\u001b[0m: 'recall'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# way to one hot encode the target variable into categorical variables\n",
    "y_train = keras.utils.to_categorical(y_train, len(np.unique(y)))\n",
    "y_val = keras.utils.to_categorical(y_val, len(np.unique(y)))\n",
    "\n",
    "\n",
    "# need to do [1:] to allow for dimensionality compatability\n",
    "a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "\n",
    "print('****** With Normalization Layer *******')\n",
    "b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "# look at keras.activations options\n",
    "# make sure to functionalize the layer object so we pass tensors\n",
    "b = keras.layers.Dense(y_train.shape[1], activation = keras.activations.softmax)(b)\n",
    "\n",
    "# utilizing stochasisity to help find the best hyper parameters will be quicker than iterating through\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "# engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "lr = .008\n",
    "\n",
    "\n",
    "# reset the model\n",
    "model = keras.Model(a,b)\n",
    "\n",
    "# Prep the model for -learning-\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "optimizer='adam',\n",
    "metrics=[keras.metrics.Precision(thresholds=0)])\n",
    "\n",
    "# urn off print because we will look at the best model\n",
    "history = model.fit(x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    verbose = 2,\n",
    "    validation_data = (x_val, y_val)\n",
    "            )\n",
    "# don't need to print out each evaluation\n",
    "score = model.evaluate(x_val, y_val, verbose = 1)\n",
    "\n",
    "plot_acc_loss(history)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3962 - recall_1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39622950553894043, 1.0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "threshold = 0.055\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns=['EmployeeID','Attrition'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "# way to one hot encode the target variable into categorical variables\n",
    "y_train = keras.utils.to_categorical(y_train, len(np.unique(y)))\n",
    "y_val = keras.utils.to_categorical(y_val, len(np.unique(y)))\n",
    "\n",
    "output = model.predict(x_val)\n",
    "\n",
    "output[output[:,1] > threshold] = [0,1]\n",
    "\n",
    "\n",
    "actual = np.argmax(y_val, axis=-1)\n",
    "predicted = np.argmax(output, axis=-1)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# incorrect = np.where(np.argmax(output,axis=-1) != np.argmax(y_val, axis=-1))\n",
    "# correct = np.where(np.argmax(output,axis=-1) == np.argmax(y_val, axis=-1))\n",
    "# print(\"Accuracy of predictions: \",(np.size(correct) / (np.size(incorrect) + np.size(correct))))\n",
    "      \n",
    "# incorrect_spots = incorrect[0]  \n",
    "      \n",
    "# print('**********Wrong Predictions**********')\n",
    "# print('Number of wrong predictions: ', np.size(incorrect_spots))\n",
    "# for i in range(np.size(incorrect_spots)):\n",
    "#     print('Predicted class value at index', incorrect_spots[i], ': ', np.argmax(output[incorrect_spots[i]]))\n",
    "#     print('Actual class value at index', incorrect_spots[i], ': ',np.argmax(y_val[incorrect_spots[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_and_test_model(data, learning_rate_range_start, learning_rate_range_end, learning_rate_step\n",
    "                          , val_accuracy_thresh, batch_size_range_start\n",
    "                          , batch_size_range_end, batch_size_step, epoch_range_start\n",
    "                          , epoch_range_end, epoch_range_step, iter_size, max_score, min_loss\n",
    "                          , best_batch_size, best_num_epochs, best_lr, best_model, best_history, normalize = False):\n",
    "    \n",
    "    # take the data and split it into training and validation sets with proper encodings\n",
    "\n",
    "    y = data['Attrition']\n",
    "    x = data.drop(columns='Attrition')\n",
    "\n",
    "    y.replace('No', 0, inplace=True)\n",
    "    y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "    # initialize the counter for the iterations, and the list to store the data   \n",
    "    iteration = 0\n",
    "    data_list = []\n",
    "\n",
    "    # create loop to go through a large ranges of batch_size and epochs combinations to find the optimal combo\n",
    "    while (max_score < val_accuracy_thresh) and (iteration < iter_size):\n",
    "\n",
    "\n",
    "        # need to do [1:] to allow for dimensionality compatability\n",
    "        a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "        \n",
    "        if normalize:\n",
    "            print('****** With Normalization Layer *******')\n",
    "            b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "        # look at keras.activations options\n",
    "        # make sure to functionalize the layer object so we pass tensors\n",
    "        b = keras.layers.Dense(1, activation = keras.activations.softmax)(b)\n",
    "    \n",
    "        # utilizing stochasisity to help find the best hyper parameters will be quicker than iterating through\n",
    "        batch_size = rand.randrange(batch_size_range_start, batch_size_range_end, batch_size_step)\n",
    "        epochs = rand.randrange(epoch_range_start, epoch_range_end, epoch_range_step)\n",
    "\n",
    "        # engineer the learning rate so that it works with floats as randrange only works with ints\n",
    "        lr = np.random.choice(np.arange(learning_rate_range_start, learning_rate_range_end, learning_rate_step), size=1)[0]\n",
    "        print(\"batch size : \", batch_size, \"...  epochs :\", epochs,\"... learning rate:\" , lr,\"...  iteration:\", iteration)\n",
    "\n",
    "        # reset the model\n",
    "        model = keras.Model(a,b)\n",
    "\n",
    "        # Prep the model for -learning-\n",
    "        model.compile(loss=keras.losses.BinaryCrossentropy(log_ints=True),\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "        metrics=[keras.metrics.Recall(thresholds=0)])\n",
    "\n",
    "        # urn off print because we will look at the best model\n",
    "        history = model.fit(x_train, y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            verbose = 2,\n",
    "            validation_data = (x_val, y_val)\n",
    "            )\n",
    "        # don't need to print out each evaluation\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        print(\"acc_score: \", score[1], \"loss_value: \", score[0])\n",
    "\n",
    "        if (score[1] > max_score):\n",
    "            max_score = score[1]\n",
    "            min_loss = score[0]\n",
    "            best_batch_size = batch_size\n",
    "            best_num_epochs = epochs\n",
    "            best_lr = lr\n",
    "            # make sure to use deepcopy so we get the object not a reference\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_history = copy.deepcopy(history)\n",
    "        \n",
    "        # increment the iteration\n",
    "        iteration += 1\n",
    "        \n",
    "        row = [score[1], score[0], batch_size, epochs, lr]\n",
    "        data_list.append(row)\n",
    "\n",
    "    # create the dataframe with the data_list\n",
    "    df = pd.DataFrame(data_list, columns=['score', 'loss', 'batch_size', 'epochs', 'learning_rate'])\n",
    "\n",
    "    return df, max_score, min_loss, best_batch_size, best_num_epochs, best_lr, best_model, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size :  12 ...  epochs : 125 ... learning rate: 0.009000000000000001 ...  iteration: 0\n",
      "acc_score:  1.0 loss_value:  523621824.0\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 18:35:56         1894\n",
      "metadata.json                                  2023-02-16 18:35:56           64\n",
      "variables.h5                                   2023-02-16 18:35:56        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 18:35:56         1894\n",
      "metadata.json                                  2023-02-16 18:35:56           64\n",
      "variables.h5                                   2023-02-16 18:35:56        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 18:35:56         1894\n",
      "metadata.json                                  2023-02-16 18:35:56           64\n",
      "variables.h5                                   2023-02-16 18:35:56        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-16 18:35:56         1894\n",
      "metadata.json                                  2023-02-16 18:35:56           64\n",
      "variables.h5                                   2023-02-16 18:35:56        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "df, max_score, min_loss, best_batch_score, best_num_epochs, best_lr,best_model, best_history = create_and_test_model(data, 0.005, 0.011, 0.001, 0.90, 2, 20, 2, 50, 300, 25, 5, 0, 100, 0, 0, 0, None, None, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 801us/step\n",
      "Accuracy of predictions:  0.0\n",
      "**********Wrong Predictions**********\n",
      "Number of wrong predictions:  336\n",
      "Predicted class value at index 0 :  0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\01_mml_initial_data_exploration.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39msize(incorrect_spots)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X44sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPredicted class value at index\u001b[39m\u001b[39m'\u001b[39m, incorrect_spots[i], \u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39margmax(output[incorrect_spots[i]]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/01_mml_initial_data_exploration.ipynb#X44sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mActual class value at index\u001b[39m\u001b[39m'\u001b[39m, incorrect_spots[i], \u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m,np\u001b[39m.\u001b[39margmax(y_val[incorrect_spots[i]]))\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# show the locations where the predictions were wrong\n",
    "\n",
    "# Validate the results of the loop\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns='Attrition')\n",
    "\n",
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.2, random_state=42)\n",
    "\n",
    "\n",
    "output = best_model.predict(x_val)\n",
    "\n",
    "incorrect = np.where(np.argmax(output,axis=-1) != np.argmax(y_val, axis=-1))\n",
    "correct = np.where(np.argmax(output,axis=-1) == np.argmax(y_val, axis=-1))\n",
    "print(\"Accuracy of predictions: \",(np.size(correct) / (np.size(incorrect) + np.size(correct))))\n",
    "      \n",
    "incorrect_spots = incorrect[0]  \n",
    "      \n",
    "print('**********Wrong Predictions**********')\n",
    "print('Number of wrong predictions: ', np.size(incorrect_spots))\n",
    "for i in range(np.size(incorrect_spots)):\n",
    "    print('Predicted class value at index', incorrect_spots[i], ': ', np.argmax(output[incorrect_spots[i]]))\n",
    "    print('Actual class value at index', incorrect_spots[i], ': ',np.argmax(y_val[incorrect_spots[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'false_positives', 'val_loss', 'val_false_positives'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>Shift</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1239491</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1552398</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1364682</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1700476</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>735</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1187985</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1463621</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1347924</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1279649</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1626443</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1856176</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1059</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeID  Age  BusinessTravel  DailyRate  Department  \\\n",
       "1572     1239491   35               1        619           1   \n",
       "283      1552398   55               1        147           2   \n",
       "797      1364682   28               2       1009           2   \n",
       "1364     1700476   34               2        735           3   \n",
       "225      1187985   59               1        142           2   \n",
       "...          ...  ...             ...        ...         ...   \n",
       "1130     1463621   43               1        990           2   \n",
       "1294     1347924   26               1        920           3   \n",
       "860      1279649   33               1        147           3   \n",
       "1459     1626443   31               3        325           1   \n",
       "1126     1856176   42               1       1059           3   \n",
       "\n",
       "      DistanceFromHome  Education  EducationField  EmployeeCount  \\\n",
       "1572                 1          3               4              1   \n",
       "283                 20          2               5              1   \n",
       "797                  1          3               3              1   \n",
       "1364                22          4               2              1   \n",
       "225                  3          3               1              1   \n",
       "...                ...        ...             ...            ...   \n",
       "1130                27          3               5              1   \n",
       "1294                20          2               3              1   \n",
       "860                  2          3               6              1   \n",
       "1459                 5          3               3              1   \n",
       "1126                 9          2               2              1   \n",
       "\n",
       "      EnvironmentSatisfaction  ...  RelationshipSatisfaction  StandardHours  \\\n",
       "1572                        2  ...                         3             80   \n",
       "283                         2  ...                         4             80   \n",
       "797                         1  ...                         1             80   \n",
       "1364                        3  ...                         2             80   \n",
       "225                         3  ...                         1             80   \n",
       "...                       ...  ...                       ...            ...   \n",
       "1130                        4  ...                         3             80   \n",
       "1294                        4  ...                         3             80   \n",
       "860                         2  ...                         4             80   \n",
       "1459                        2  ...                         2             80   \n",
       "1126                        4  ...                         4             80   \n",
       "\n",
       "      Shift  TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "1572      0                 15                      2                3   \n",
       "283       1                 12                      4                3   \n",
       "797       2                  1                      2                3   \n",
       "1364      0                 16                      3                3   \n",
       "225       1                  7                      6                3   \n",
       "...     ...                ...                    ...              ...   \n",
       "1130      1                  8                      0                3   \n",
       "1294      0                  6                      3                3   \n",
       "860       1                  5                      2                3   \n",
       "1459      0                 10                      2                3   \n",
       "1126      0                 24                      2                3   \n",
       "\n",
       "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "1572              11                   9                        6   \n",
       "283               10                   7                        0   \n",
       "797                1                   0                        0   \n",
       "1364              15                  10                        6   \n",
       "225                1                   0                        0   \n",
       "...              ...                 ...                      ...   \n",
       "1130               6                   4                        0   \n",
       "1294               5                   1                        1   \n",
       "860                5                   4                        1   \n",
       "1459               9                   4                        1   \n",
       "1126               1                   0                        0   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "1572                     9  \n",
       "283                      8  \n",
       "797                      0  \n",
       "1364                    11  \n",
       "225                      0  \n",
       "...                    ...  \n",
       "1130                     2  \n",
       "1294                     4  \n",
       "860                      4  \n",
       "1459                     7  \n",
       "1126                     1  \n",
       "\n",
       "[335 rows x 34 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a74b6a200323c7ff9fb958487b2523ec46e5f6d52f4531a6be995daba14337f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
