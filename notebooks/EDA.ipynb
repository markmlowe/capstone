{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"c:\\\\Users\\\\markm\\\\Desktop\\\\CAPSTONE\\\\capstone\\\\data\\\\external\\\\watson_healthcare_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>Shift</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313919</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200302</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060315</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272912</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1414939</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  Age Attrition     BusinessTravel  DailyRate  Department  \\\n",
       "0     1313919   41        No      Travel_Rarely       1102  Cardiology   \n",
       "1     1200302   49        No  Travel_Frequently        279   Maternity   \n",
       "2     1060315   37       Yes      Travel_Rarely       1373   Maternity   \n",
       "3     1272912   33        No  Travel_Frequently       1392   Maternity   \n",
       "4     1414939   27        No      Travel_Rarely        591   Maternity   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  ...  \\\n",
       "0                 1          2  Life Sciences              1  ...   \n",
       "1                 8          1  Life Sciences              1  ...   \n",
       "2                 2          2          Other              1  ...   \n",
       "3                 3          4  Life Sciences              1  ...   \n",
       "4                 2          1        Medical              1  ...   \n",
       "\n",
       "   RelationshipSatisfaction StandardHours  Shift  TotalWorkingYears  \\\n",
       "0                         1            80      0                  8   \n",
       "1                         4            80      1                 10   \n",
       "2                         2            80      0                  7   \n",
       "3                         3            80      0                  8   \n",
       "4                         4            80      1                  6   \n",
       "\n",
       "   TrainingTimesLastYear WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                      0               1               6                  4   \n",
       "1                      3               3              10                  7   \n",
       "2                      3               3               0                  0   \n",
       "3                      3               3               8                  7   \n",
       "4                      3               3               2                  2   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                     5  \n",
       "1                        1                     7  \n",
       "2                        0                     0  \n",
       "3                        3                     0  \n",
       "4                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeID                1676 non-null   int64 \n",
      " 1   Age                       1676 non-null   int64 \n",
      " 2   Attrition                 1676 non-null   object\n",
      " 3   BusinessTravel            1676 non-null   object\n",
      " 4   DailyRate                 1676 non-null   int64 \n",
      " 5   Department                1676 non-null   object\n",
      " 6   DistanceFromHome          1676 non-null   int64 \n",
      " 7   Education                 1676 non-null   int64 \n",
      " 8   EducationField            1676 non-null   object\n",
      " 9   EmployeeCount             1676 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1676 non-null   int64 \n",
      " 11  Gender                    1676 non-null   object\n",
      " 12  HourlyRate                1676 non-null   int64 \n",
      " 13  JobInvolvement            1676 non-null   int64 \n",
      " 14  JobLevel                  1676 non-null   int64 \n",
      " 15  JobRole                   1676 non-null   object\n",
      " 16  JobSatisfaction           1676 non-null   int64 \n",
      " 17  MaritalStatus             1676 non-null   object\n",
      " 18  MonthlyIncome             1676 non-null   int64 \n",
      " 19  MonthlyRate               1676 non-null   int64 \n",
      " 20  NumCompaniesWorked        1676 non-null   int64 \n",
      " 21  Over18                    1676 non-null   object\n",
      " 22  OverTime                  1676 non-null   object\n",
      " 23  PercentSalaryHike         1676 non-null   int64 \n",
      " 24  PerformanceRating         1676 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1676 non-null   int64 \n",
      " 26  StandardHours             1676 non-null   int64 \n",
      " 27  Shift                     1676 non-null   int64 \n",
      " 28  TotalWorkingYears         1676 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1676 non-null   int64 \n",
      " 30  WorkLifeBalance           1676 non-null   int64 \n",
      " 31  YearsAtCompany            1676 non-null   int64 \n",
      " 32  YearsInCurrentRole        1676 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1676 non-null   int64 \n",
      " 34  YearsWithCurrManager      1676 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 458.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Attrition']\n",
    "x = data.drop(columns='Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 34)\n",
      "(1676,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\markm\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:07<00:00,  3.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.71               0.77     0.77      0.76   \n",
       "SGDClassifier                      0.90               0.77     0.77      0.90   \n",
       "BernoulliNB                        0.90               0.76     0.76      0.90   \n",
       "LinearSVC                          0.90               0.75     0.75      0.90   \n",
       "LogisticRegression                 0.92               0.75     0.75      0.91   \n",
       "Perceptron                         0.90               0.75     0.75      0.90   \n",
       "AdaBoostClassifier                 0.91               0.73     0.73      0.90   \n",
       "LinearDiscriminantAnalysis         0.90               0.72     0.72      0.89   \n",
       "PassiveAggressiveClassifier        0.89               0.72     0.72      0.89   \n",
       "LGBMClassifier                     0.91               0.69     0.69      0.90   \n",
       "XGBClassifier                      0.91               0.68     0.68      0.90   \n",
       "DecisionTreeClassifier             0.86               0.67     0.67      0.86   \n",
       "ExtraTreeClassifier                0.84               0.64     0.64      0.84   \n",
       "BaggingClassifier                  0.90               0.63     0.63      0.88   \n",
       "ExtraTreesClassifier               0.91               0.63     0.63      0.88   \n",
       "RandomForestClassifier             0.90               0.60     0.60      0.87   \n",
       "GaussianNB                         0.35               0.60     0.60      0.40   \n",
       "CalibratedClassifierCV             0.89               0.59     0.59      0.86   \n",
       "LabelPropagation                   0.86               0.58     0.58      0.84   \n",
       "LabelSpreading                     0.85               0.58     0.58      0.84   \n",
       "RidgeClassifier                    0.89               0.57     0.57      0.86   \n",
       "RidgeClassifierCV                  0.89               0.55     0.55      0.85   \n",
       "KNeighborsClassifier               0.88               0.53     0.53      0.83   \n",
       "SVC                                0.88               0.51     0.51      0.82   \n",
       "DummyClassifier                    0.88               0.50     0.50      0.82   \n",
       "QuadraticDiscriminantAnalysis      0.88               0.50     0.50      0.82   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.10  \n",
       "SGDClassifier                        0.11  \n",
       "BernoulliNB                          0.11  \n",
       "LinearSVC                            0.13  \n",
       "LogisticRegression                   0.19  \n",
       "Perceptron                           0.08  \n",
       "AdaBoostClassifier                   0.68  \n",
       "LinearDiscriminantAnalysis           0.55  \n",
       "PassiveAggressiveClassifier          0.09  \n",
       "LGBMClassifier                       0.38  \n",
       "XGBClassifier                        0.95  \n",
       "DecisionTreeClassifier               0.13  \n",
       "ExtraTreeClassifier                  0.16  \n",
       "BaggingClassifier                    0.22  \n",
       "ExtraTreesClassifier                 0.75  \n",
       "RandomForestClassifier               0.79  \n",
       "GaussianNB                           0.13  \n",
       "CalibratedClassifierCV               0.25  \n",
       "LabelPropagation                     0.23  \n",
       "LabelSpreading                       0.19  \n",
       "RidgeClassifier                      0.11  \n",
       "RidgeClassifierCV                    0.12  \n",
       "KNeighborsClassifier                 0.38  \n",
       "SVC                                  0.19  \n",
       "DummyClassifier                      0.09  \n",
       "QuadraticDiscriminantAnalysis        0.11  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.8, random_state=42)\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "models, predictions = clf.fit(x_train,x_test,y_train,y_test)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeID                1676 non-null   int64 \n",
      " 1   Age                       1676 non-null   int64 \n",
      " 2   Attrition                 1676 non-null   int64 \n",
      " 3   BusinessTravel            1676 non-null   object\n",
      " 4   DailyRate                 1676 non-null   int64 \n",
      " 5   Department                1676 non-null   object\n",
      " 6   DistanceFromHome          1676 non-null   int64 \n",
      " 7   Education                 1676 non-null   int64 \n",
      " 8   EducationField            1676 non-null   object\n",
      " 9   EmployeeCount             1676 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1676 non-null   int64 \n",
      " 11  Gender                    1676 non-null   object\n",
      " 12  HourlyRate                1676 non-null   int64 \n",
      " 13  JobInvolvement            1676 non-null   int64 \n",
      " 14  JobLevel                  1676 non-null   int64 \n",
      " 15  JobRole                   1676 non-null   object\n",
      " 16  JobSatisfaction           1676 non-null   int64 \n",
      " 17  MaritalStatus             1676 non-null   object\n",
      " 18  MonthlyIncome             1676 non-null   int64 \n",
      " 19  MonthlyRate               1676 non-null   int64 \n",
      " 20  NumCompaniesWorked        1676 non-null   int64 \n",
      " 21  Over18                    1676 non-null   object\n",
      " 22  OverTime                  1676 non-null   object\n",
      " 23  PercentSalaryHike         1676 non-null   int64 \n",
      " 24  PerformanceRating         1676 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1676 non-null   int64 \n",
      " 26  StandardHours             1676 non-null   int64 \n",
      " 27  Shift                     1676 non-null   int64 \n",
      " 28  TotalWorkingYears         1676 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1676 non-null   int64 \n",
      " 30  WorkLifeBalance           1676 non-null   int64 \n",
      " 31  YearsAtCompany            1676 non-null   int64 \n",
      " 32  YearsInCurrentRole        1676 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1676 non-null   int64 \n",
      " 34  YearsWithCurrManager      1676 non-null   int64 \n",
      "dtypes: int64(27), object(8)\n",
      "memory usage: 458.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nurse</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Maternity</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel  Department EducationField  Gender JobRole MaritalStatus  \\\n",
       "0      Travel_Rarely  Cardiology  Life Sciences  Female   Nurse        Single   \n",
       "1  Travel_Frequently   Maternity  Life Sciences    Male   Other       Married   \n",
       "\n",
       "  Over18 OverTime  \n",
       "0      Y      Yes  \n",
       "1      Y       No  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(include=['object']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department:  ['Cardiology' 'Maternity' 'Neurology']\n",
      "Business Data:  ['Travel_Rarely' 'Travel_Frequently' 'Non-Travel']\n",
      "EducationField:  ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'\n",
      " 'Human Resources']\n",
      "Gender:  ['Female' 'Male']\n",
      "JobRole:  ['Nurse' 'Other' 'Therapist' 'Administrative' 'Admin']\n",
      "MaritalStatus\t:  ['Single' 'Married' 'Divorced']\n",
      "Over18:  ['Y']\n",
      "OverTime:  ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(\"Department: \", data.Department.unique())\n",
    "print(\"Business Data: \",data.BusinessTravel.unique())\n",
    "print(\"EducationField: \",data.EducationField.unique())\n",
    "print(\"Gender: \",data.Gender.unique())\n",
    "print(\"JobRole: \",data.JobRole.unique())\n",
    "print(\"MaritalStatus\t: \",data.MaritalStatus\t.unique())\n",
    "print(\"Over18: \",data.Over18.unique())\n",
    "print(\"OverTime: \", data.OverTime.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- Because we don't see many unique responses to any of these variables, *with Educational Field having the most with 6*, I am going to encode these variables in place rather than using get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script for parsing data for neural networks\n",
    "def convert_numeric(data):\n",
    "\n",
    "    convert_obj = {\"Department\" : {\"Cardiology\" : 1, \"Maternity\" : 2, \"Neurology\" : 3},\n",
    "                   \"BusinessTravel\" : {\"Travel_Rarely\" : 1, \"Travel_Frequently\" : 2, \"Non-Travel\" : 3},\n",
    "                   \"EducationField\" : {\"Life Sciences\" : 1, \"Other\" : 2, \"Medical\" : 3, \"Marketing\" : 4,\n",
    "                                        \"Technical Degree\" : 5, \"Human Resources\" : 6},\n",
    "                    \"Gender\" : {\"Female\" : 1, \"Male\" : 2},\n",
    "                    \"JobRole\" : {\"Nurse\" : 1, \"Other\" : 2, \"Therapist\" : 3, \"Administrative\" : 4, \"Admin\" : 5},\n",
    "                    \"MaritalStatus\" : {\"Single\" : 1, \"Married\" : 2, \"Divorced\" : 4},\n",
    "                    \"Over18\" : {\"Y\" : 1},\n",
    "                    \"OverTime\" : {\"Yes\" : 1, \"No\" : 0}\n",
    "        \n",
    "    }\n",
    "\n",
    "    data = data.replace(convert_obj)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_numeric(data)\n",
    "\n",
    "y = data['Attrition']\n",
    "x = data.drop(columns='Attrition')\n",
    "\n",
    "y.replace('No', 0, inplace=True)\n",
    "y.replace('Yes', 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import copy\n",
    "import random as rand\n",
    "\n",
    "def create_and_test_model(data, learning_rate_range_start, learning_rate_range_end, learning_rate_step\n",
    "                          , val_accuracy_thresh, batch_size_range_start\n",
    "                          , batch_size_range_end, batch_size_step, epoch_range_start\n",
    "                          , epoch_range_end, epoch_range_step, max_score, min_loss\n",
    "                          , best_batch_size, best_num_epochs, best_model, best_history, normalize = False):\n",
    "    \n",
    "    # take the data and split it into training and validation sets with proper encodings\n",
    "    \n",
    "    y = data['Attrition']\n",
    "    x = data.drop(columns='Attrition')\n",
    "\n",
    "    y.replace('No', 0, inplace=True)\n",
    "    y.replace('Yes', 1, inplace = True)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y, test_size =0.8, random_state=42)\n",
    "    \n",
    "    # way to one hot encode the target variable into categorical variables\n",
    "    y_train = keras.utils.to_categorical(y_train, len(np.unique(y)))\n",
    "    y_val = keras.utils.to_categorical(y_val, len(np.unique(y)))\n",
    "    \n",
    "\n",
    "    \n",
    "    iteration = 0\n",
    "    # create loop to go through a large ranges of batch_size and epochs combinations to find the optimal combo\n",
    "    while (max_score < val_accuracy_thresh) | (iteration < 100):\n",
    "        # increment the iteration\n",
    "        iteration += 1\n",
    "            # need to do [1:] to allow for dimensionality compatability\n",
    "        a = b = keras.layers.Input(shape = x_train.shape[1:])\n",
    "        \n",
    "        if normalize:\n",
    "            print('****** With Normalization Layer *******')\n",
    "            b = keras.layers.LayerNormalization(axis= -1)(b)\n",
    "\n",
    "        # look at keras.activations options\n",
    "        # make sure to functionalize the layer object so we pass tensors\n",
    "        b = keras.layers.Dense(y_train.shape[1], activation = keras.activations.softmax)(b)\n",
    "    \n",
    "        batch_size = rand.randrange(batch_size_range_start, batch_size_range_end, batch_size_step)\n",
    "        epochs = rand.randrange(epoch_range_start, epoch_range_end, epoch_range_step)\n",
    "        lr = rand.randrange(learning_rate_range_start, learning_rate_range_end, learning_rate_step)\n",
    "        print(\"batch size : \", batch_size, \"...  epochs :\", epochs, \"...  iteration:\", iteration)\n",
    "        # reset the model\n",
    "        model = keras.Model(a,b)\n",
    "\n",
    "        # Prep the model for -learning-\n",
    "        model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "                metrics=keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "\n",
    "        # Train the model and record the training\n",
    "        # urn off print because we will look at the best model\n",
    "        history = model.fit(x_train, y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            verbose = 0,\n",
    "            validation_data = (x_val, y_val)\n",
    "                    )\n",
    "        # don't need to print out each evaluation\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "\n",
    "        if (score[1] > max_score):\n",
    "            max_score = score[1]\n",
    "            min_loss = score[0]\n",
    "            best_batch_score = batch_size\n",
    "            best_num_epochs = epochs\n",
    "            # make sure to use deepcopy so we get the object not a reference\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_history = copy.deepcopy(history)\n",
    "        \n",
    "    return max_score, min_loss, best_batch_score, best_num_epochs, best_model, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size :  2 ...  epochs : 20\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-08 10:49:45         1901\n",
      "metadata.json                                  2023-02-08 10:49:45           64\n",
      "variables.h5                                   2023-02-08 10:49:45        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-08 10:49:44         1901\n",
      "metadata.json                                  2023-02-08 10:49:44           64\n",
      "variables.h5                                   2023-02-08 10:49:44        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-08 10:49:45         1901\n",
      "metadata.json                                  2023-02-08 10:49:45           64\n",
      "variables.h5                                   2023-02-08 10:49:45        16416\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-08 10:49:44         1901\n",
      "metadata.json                                  2023-02-08 10:49:44           64\n",
      "variables.h5                                   2023-02-08 10:49:44        16416\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...metrics\\categorical_accuracy\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...vars\n",
      "batch size :  2 ...  epochs : 25\n",
      "batch size :  2 ...  epochs : 30\n",
      "batch size :  2 ...  epochs : 35\n",
      "batch size :  2 ...  epochs : 40\n",
      "batch size :  2 ...  epochs : 45\n",
      "batch size :  2 ...  epochs : 50\n",
      "batch size :  2 ...  epochs : 55\n",
      "batch size :  2 ...  epochs : 60\n",
      "batch size :  2 ...  epochs : 65\n",
      "batch size :  2 ...  epochs : 70\n",
      "batch size :  2 ...  epochs : 75\n",
      "batch size :  4 ...  epochs : 20\n",
      "batch size :  4 ...  epochs : 25\n",
      "batch size :  4 ...  epochs : 30\n",
      "batch size :  4 ...  epochs : 35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\EDA.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m max_score, min_loss, best_batch_score, best_num_epochs, best_model, best_history \u001b[39m=\u001b[39m create_and_test_model(data, \u001b[39m2\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m80\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, normalize \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\markm\\Desktop\\CAPSTONE\\capstone\\notebooks\\EDA.ipynb Cell 26\u001b[0m in \u001b[0;36mcreate_and_test_model\u001b[1;34m(data, batch_size_range_start, batch_size_range_end, epoch_range_start, epoch_range_end, max_score, min_loss, best_batch_size, best_num_epochs, best_model, best_history, normalize)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m           optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m           metrics\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mCategoricalAccuracy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Train the model and record the training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# urn off print because we will look at the best model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m       batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m       epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m       verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m       validation_data \u001b[39m=\u001b[39;49m (x_val, y_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# don't need to print out each evaluation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markm/Desktop/CAPSTONE/capstone/notebooks/EDA.ipynb#X35sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_val, y_val, verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1693\u001b[0m     )\n\u001b[1;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1706\u001b[0m )\n\u001b[0;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1709\u001b[0m }\n\u001b[0;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2045\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                 \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m                 logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m-> 2045\u001b[0m                 end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39;49mstep_increment\n\u001b[0;32m   2046\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_end(end_step, logs)\n\u001b[0;32m   2048\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n",
      "File \u001b[1;32mc:\\Users\\markm\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1391\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m steps_remaining\n\u001b[0;32m   1389\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution\u001b[39m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1391\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   1392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_increment\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1393\u001b[0m     \u001b[39m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_score, min_loss, best_batch_score, best_num_epochs, best_model, best_history = create_and_test_model(data, 2, 500, 20, 200, 0, 100, 0, 0, None, None, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a74b6a200323c7ff9fb958487b2523ec46e5f6d52f4531a6be995daba14337f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
